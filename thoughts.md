# 技术思考记录

---

## 1. 技术选型：RAG vs. 微调

#### 核心问题
应该采用RAG还是微调

核心：RAG无法学习风格和格式

#### 结论摘要

- **RAG (检索增强生成)**
  - **模式**：“开卷考试”，实时检索外部知识库作答。
  - **优势**：保证信息**实时、准确**，成本低。
  - **劣势**：依赖检索效果，检索器的设计很重要。

- **微调 (Fine-Tuning)**
  - **模式**：“闭卷考试”，将知识内化到模型中。
  - **优势**：深度学习**文笔风格**。
  - **劣势**：知识**会过时**，成本高。

- **本项目选型**
  - **首选**：**RAG**。满足内容准确、信息常新的核心需求。
  - **进阶**：**RAG + 微调**。用RAG保证内容，用微调优化文笔。

---
## 2. 文本分块

### 核心挑战：精度 vs. 上下文

文本分块的关键在于平衡“检索精度”和“上下文完整性”。
- **小块 (Smaller Chunks)**：信息聚焦，提高检索精度，但可能丢失上下文。
- **大块 (Larger Chunks)**：上下文完整，但可能包含噪音，降低检索精度。

### 基础分块策略

1.  **固定大小分块 (Fixed-size Chunking)**
    - **方法**：按固定字符数切分，可设重叠部分（Overlap）。
    - **优劣**：实现简单，但容易破坏语义完整性。

2.  **基于句子的分块 (Sentence Splitting)**
    - **方法**：按句子边界（如`.?!`）切分，再将句子组合成块。
    - **优劣**：能较好保持语义，但块大小不均匀。

3.  **递归字符分块 (Recursive Character Splitting)**
    - **方法**：按优先级列表（如 `\n\n`, `\n`, ` `）递归分割，试图在保持结构的同时满足大小限制。 
    - **优劣**：通用性好，是固定大小和句子分割的良好折中。LangChain等框架常用。

4.  **基于文档结构的分块 (Document Structure-aware)**
    - **方法**：利用文档自身结构（如Markdown的`#`, `##`，HTML的`<p>`）来分割。
    - **优劣**：能最好地保持原文结构和语义，但依赖于清晰的文档结构。

5.  **混合分块 (Hybrid Chunking)**
    - **方法**：结合多种策略。例如，先按文档结构（标题）做粗粒度切分，再对过大的块用递归字符分块做细粒度切分。
    - **优劣**：兼顾结构与大小，灵活性高，是目前比较理想的方案。`mdsplit.py` 就是这种思路的实现。

### 高级分块策略

1.  **语义分块 (Semantic Chunking)**
    - **核心思想**：计算相邻句子/段落的向量相似度，在“话题”转变（相似度低于阈值）处切分。
    - **特点**：质量高，但计算开销大。

2.  **分层分块 (Hierarchical Chunking) & Small-to-Big检索**
    - **核心思想**：检索时，先匹配精确的“小块”（如句子），然后返回其所属的、包含更丰富上下文的“父块”（如整个段落）给LLM。
    - **特点**：结合了小块的**检索精度**和大块的**上下文完整性**。

3.  **命题分块 (Proposition Chunking)**
    - **核心思想**：利用LLM将文本分解为最小的、原子性的事实陈述（命题），然后对命题进行索引。
    - **特点**：极为精确，适合事实性问答，但成本高昂且可能丢失原文语气。

4.  **Agentic / LLM-based Chunking**
    - **核心思想**：让一个Agent或LLM根据对内容的理解来动态决策如何分块。
    - **特点**：理论上最智能，但实现复杂、成本高，仍处于探索阶段。

### 优化策略

- **上下文富化 (Context Enrichment)**：分块后，为每个块补充额外信息，如所属章节标题、相邻句子摘要等，作为元数据。
<<<<<<< HEAD
=======

## 3.调用llm优化时，总是会多余返回评价等不属于文章内容的部分，而且会对成段的内容做切分
>>>>>>> 8a00a7c (RAG is bad for solution)
